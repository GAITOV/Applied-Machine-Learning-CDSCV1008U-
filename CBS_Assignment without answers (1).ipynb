{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ-PuwoyX4qQ"
   },
   "source": [
    "# Workshop CBS / Capgemini\n",
    "\n",
    "In this Workshop/Exercise you will get to practice using [TensorFlow Data Validation (TFDV)](https://cloud.google.com/solutions/machine-learning/analyzing-and-validating-data-at-scale-for-ml-using-tfx), an open-source Python package from the [TensorFlow Extended (TFX)](https://www.tensorflow.org/tfx) ecosystem. \n",
    "It is an open-source library that helps to understand, validate, and monitor production machine learning (ML) data at scale. Common use-cases include comparing training, evaluation and serving datasets, as well as checking for training/serving skew. \n",
    "\n",
    "In this exercise you will use TFDV in order to:\n",
    "\n",
    "* Generate and visualize statistics from a dataframe\n",
    "* Infer a dataset schema\n",
    "* Calculate, visualize and fix anomalies\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEr9hlCHBZ-K"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Setup and Imports](#1)\n",
    "- [2 - Load the Dataset](#2)\n",
    "  - [2.1 - Read and Split the Dataset](#2-1)\n",
    "    - [2.1.1 - Data Splits](#2-1-1)\n",
    "    - [2.1.2 - Label Column](#2-1-2)\n",
    "- [3 - Generate and Visualize Training Data Statistics](#3)\n",
    "  - [3.1 - Removing Irrelevant Features](#3-1)\n",
    "  - [Generate Training Statistics](#ex-1)\n",
    "  - [Visualize Training Statistics](#ex-2)\n",
    "- [4 - Infer a Data Schema](#4)\n",
    "  - [Infer the training set schema](#ex-3)\n",
    "- [5 - Calculate, Visualize and Fix Evaluation Anomalies](#5)\n",
    "  - [Compare Training and Evaluation Statistics](#ex-4)\n",
    "  - [Detecting Anomalies](#ex-5)\n",
    "  - [Fix evaluation anomalies in the schema](#ex-6)\n",
    "- [6 - Schema Environments](#6)\n",
    "  - [Check anomalies in the serving set](#ex-7)\n",
    "  - [Modifying the domain](#ex-8)\n",
    "  - [Detecting anomalies with environments](#ex-9)\n",
    "- [7 - Check for Data Drift and Skew](#7)\n",
    "- [8 - Freeze the Schema](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEnMK4DRNV1O"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Setup and Imports\n",
    "\n",
    "Note, if you have not used the packages before, you need to install them first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "zrLPRsQgImel",
    "outputId": "1cbc6099-5689-4fb8-a362-5d13ecf5356b"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "#!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import tempfile, urllib, zipfile\n",
    "#!pip install tensorflow_data_validation\n",
    "import tensorflow_data_validation as tfdv\n",
    "\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow_data_validation.utils import slicing_util\n",
    "from tensorflow_metadata.proto.v0.statistics_pb2 import DatasetFeatureStatisticsList, DatasetFeatureStatistics\n",
    "\n",
    "# Set TF's logger to only display errors to avoid internal warnings being shown\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MizoHg1DRlK"
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Load the Dataset\n",
    "You will be using the [Diabetes 130-US hospitals for years 1999-2008 Data Set](https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008) donated to the University of California, Irvine (UCI) Machine Learning Repository. The dataset represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2o2NGqIxc5e"
   },
   "source": [
    "<a name='2-1'></a>\n",
    "### 2.1 Read and Split the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTj6V6HwBZ-6"
   },
   "source": [
    "Start by downloading the dataset from the website: [Diabetes 130-US hospitals for years 1999-2008 Data Set](https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008). It is then important to change the filepath to read the dataset.   \n",
    "\n",
    "**Task**: Read the data and then preview the data by using `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "YyO3RSuLF0Nf",
    "outputId": "5dd8da09-f242-4d5b-912c-547615893fab"
   },
   "outputs": [],
   "source": [
    "# Read CSV data into a dataframe and recognize the missing data that is encoded with '?' string as NaN\n",
    "df = pd.read_csv('diabetic_data.csv', header=0, na_values = '?')\n",
    "\n",
    "# Preview the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-7q-_SqBZ_Q"
   },
   "source": [
    "<a name='2-1-1'></a>\n",
    "#### Data splits\n",
    "\n",
    "In a production ML system, the model performance can be negatively affected by anomalies and divergence between data splits for training, evaluation, and serving. To emulate a production system, you will split the dataset into:\n",
    "\n",
    "* 70% training set \n",
    "* 15% evaluation set\n",
    "* 15% serving set\n",
    "\n",
    "You will then use TFDV to visualize, analyze, and understand the data. You will create a data schema from the training dataset, then compare the evaluation and serving sets with this schema to detect anomalies and data drift/skew.\n",
    "\n",
    "<a name='2-1-2'></a>\n",
    "#### Label Column\n",
    "\n",
    "This dataset has been prepared to analyze the factors related to readmission outcome. In this notebook, you will treat the `readmitted` column as the *target* or label column. \n",
    "\n",
    "The target (or label) is important to know while splitting the data into training, evaluation and serving sets. In supervised learning, you need to include the target in the training and evaluation datasets. For the serving set however (i.e. the set that simulates the data coming from your users), the **label column needs to be dropped** since that is the feature that your model will be trying to predict.\n",
    "\n",
    "**Task**: Split the dataset and return the training, evaluation and serving data:\n",
    "* train_df: Training dataframe(70% of the entire dataset)\n",
    "* eval_df: Evaluation dataframe (15% of the entire dataset) \n",
    "* serving_df: Serving dataframe (15% of the entire dataset, label column dropped)\n",
    "\n",
    "**Drop the label column in the serving data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tv1I6Dd2IS5J",
    "outputId": "718b1ee6-dd8d-4e67-be05-7e492390c661"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fq-fztIzBZ_n"
   },
   "source": [
    "How many records are in each of the three datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJV6__uVhz0B",
    "outputId": "e23563b5-f6b6-4127-8c67-312cb8318f1e"
   },
   "outputs": [],
   "source": [
    "# Find the amount of records in each dataset:\n",
    "print('Training dataset has {} records\\nValidation dataset has {} records\\nServing dataset has {} records'.format(len(train_df),len(eval_df),len(serving_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nnln8dH8Nmm8"
   },
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Generate and Visualize Training Data Statistics\n",
    "\n",
    "In this section, you will be generating descriptive statistics from the dataset. This is usually the first step when dealing with a dataset you are not yet familiar with. It is also known as performing an *exploratory data analysis* and its purpose is to understand the data types, the data itself and any possible issues that need to be addressed.\n",
    "\n",
    "It is important to mention that **exploratory data analysis should be perfomed on the training dataset** only. This is because getting information out of the evaluation or serving datasets can be seen as \"cheating\" since this data is used to emulate data that you have not collected yet and will try to predict using your ML algorithm. **In general, it is a good practice to avoid leaking information from your evaluation and serving data into your model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCrnVmQUY4We"
   },
   "source": [
    "<a name='3-1'></a>\n",
    "### Removing Irrelevant Features\n",
    "\n",
    "Before you generate the statistics, you want to drop irrelevant features from your dataset. You can do that with TFDV with the [tfdv.StatsOptions](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/StatsOptions) class. It is usually **not a good idea** to drop features without knowing what information they contain. However there are times when this can be fairly obvious.\n",
    "\n",
    "One of the important parameters of the `StatsOptions` class is `feature_allowlist`, which defines the features to include while calculating the data statistics. You can check the [documentation](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/StatsOptions#args) to learn more about the class arguments.\n",
    "\n",
    "**Task**: Omit the variables `encounter_id` and `patient_nbr` from the data since they are part of the internal tracking of patients in the hospital and they don't contain valuable information for the task at hand. Use the  function [tfdv.StatsOptions](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/StatsOptions) on the remaining columns and name it *stats_options*. Then review the features by calling them out with `feature_allowlist`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "z4jKM0gyj8Qc",
    "outputId": "2f7dc95a-e8c1-47a4-f6ef-514744aab916"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvHoWMcYNzIx"
   },
   "source": [
    "<a name='ex-1'></a>\n",
    "### Generate Training Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO44zMHCBaAB"
   },
   "source": [
    "TFDV allows you to generate statistics from different data formats such as CSV or a Pandas DataFrame. \n",
    "\n",
    "Since you already have the data stored in a DataFrame you can use the function [`tfdv.generate_statistics_from_dataframe()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/generate_statistics_from_dataframe) which, given a DataFrame and `stats_options`, generates an object of type `DatasetFeatureStatisticsList`. This object includes the computed statistics of the given dataset.\n",
    "\n",
    "**Task**: Generate the statistics of the training set and name it *train_stats*. Remember to pass the training dataframe and the `stats_options` that you defined above as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EE481oMbT-H0",
    "outputId": "c2b32d88-385b-4d83-9444-0c9b8987b1c7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo1c_892BaAE"
   },
   "source": [
    "You can test your code with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gY0KGUhvBaAO",
    "outputId": "42f48b95-a9c9-45d9-b788-3fc443880135"
   },
   "outputs": [],
   "source": [
    "# get the number of features used to compute statistics\n",
    "print(f\"Number of features used: {len(train_stats.datasets[0].features)}\")\n",
    "\n",
    "# check the number of examples used\n",
    "print(f\"Number of examples used: {train_stats.datasets[0].num_examples}\")\n",
    "\n",
    "# check the column names of the first and last feature\n",
    "print(f\"First feature: {train_stats.datasets[0].features[0].path.step[0]}\")\n",
    "print(f\"Last feature: {train_stats.datasets[0].features[-1].path.step[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQt4LJguBaAU"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "Number of features used: 48\n",
    "Number of examples used: 71236\n",
    "First feature: race\n",
    "Last feature: readmitted\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElOMvBOKNvLp"
   },
   "source": [
    "<a name='ex-2'></a>\n",
    "### Visualize Training Statistics\n",
    "\n",
    "Now that you have the computed statistics in the `DatasetFeatureStatisticsList` instance, you will need a way to **visualize** these to get actual insights. TFDV provides this functionality through the method [`tfdv.visualize_statistics()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/visualize_statistics).\n",
    "\n",
    "Using this function in an interactive Python environment such as this one will output a very nice and convenient way to interact with the descriptive statistics you generated earlier. \n",
    "\n",
    "**Task**: Visualize the training statistics with the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "graded": true,
    "id": "U3tUKgh7Up3x",
    "name": "train_stats_visualize_statistics",
    "outputId": "55a1bca6-d981-4cce-82e9-84b9046c3c72"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVR02-y4V0uM"
   },
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Infer a data schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPRioB7hZ03b"
   },
   "source": [
    "A schema defines the **properties of the data** and can thus be used to detect errors. Some of these properties include:\n",
    "\n",
    "- which features are expected to be present\n",
    "- feature type\n",
    "- the number of values for a feature in each example\n",
    "- the presence of each feature across all examples\n",
    "- the expected domains of features\n",
    "\n",
    "The schema is expected to be fairly static, whereas statistics can vary per data split. So, you will **infer the data schema from only the training dataset**. Later, you will generate statistics for evaluation and serving datasets and compare their state with the data schema to detect anomalies, drift and skew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdD_Wp_VBaAb"
   },
   "source": [
    "<a name='ex-3'></a>\n",
    "### Infer the training set schema\n",
    "\n",
    "Schema inference is straightforward using [`tfdv.infer_schema()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/infer_schema). This function needs only the **statistics** (an instance of `DatasetFeatureStatisticsList`) of your data as input. The output will be a Schema [protocol buffer](https://developers.google.com/protocol-buffers) containing the results.\n",
    "\n",
    "A complimentary function is [`tfdv.display_schema()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/display_schema) for displaying the schema in a table. This accepts a **Schema** protocol buffer as input.\n",
    "\n",
    "**Task**: Infer the training schema and name it *schema*. Then display the data schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "6LLkRJThVr9m",
    "outputId": "8559737e-5970-42ba-d664-b58ea0e609cc"
   },
   "outputs": [],
   "source": [
    "# Infer the data schema by using the training statistics that you generated\n",
    "\n",
    "\n",
    "# Display the data schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jfky_JyqBaAd"
   },
   "source": [
    "In the following you can test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "dk_gavvlBaAe",
    "outputId": "0133c62c-b451-4604-e6cb-09979eaa85b4"
   },
   "outputs": [],
   "source": [
    "# Check number of features\n",
    "print(f\"Number of features in schema: {len(schema.feature)}\")\n",
    "\n",
    "# Check domain name of 2nd feature\n",
    "print(f\"Second feature in schema: {list(schema.feature)[1].domain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iav7Rk2CBaAh"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "Number of features in schema: 48\n",
    "Second feature in schema: gender\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVa3EXE8WEDE"
   },
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Calculate, Visualize and Fix Evaluation Anomalies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PG0tVZDaDTF"
   },
   "source": [
    "It is important that the schema of the evaluation data is consistent with the training data since the data that your model is going to receive should be consistent to the one you used to train it with.\n",
    "\n",
    "Moreover, it is also important that the **features of the evaluation data belong roughly to the same range as the training data**. This ensures that the model will be evaluated on a similar loss surface covered during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvBf5HpzBaAh"
   },
   "source": [
    "<a name='ex-4'></a>\n",
    "### Compare Training and Evaluation Statistics\n",
    "\n",
    "Now you are going to generate the evaluation statistics and compare it with training statistics. You can use the [`tfdv.generate_statistics_from_dataframe()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/generate_statistics_from_dataframe) function for this. But this time, you'll need to pass the **evaluation data**. For the `stats_options` parameter, the list you used before works here too.\n",
    "\n",
    "Remember that to visualize the evaluation statistics you can use [`tfdv.visualize_statistics()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/visualize_statistics). \n",
    "\n",
    "However, it is impractical to visualize both statistics separately and do your comparison from there. Fortunately, TFDV has got this covered. You can use the `visualize_statistics` function and pass additional parameters to overlay the statistics from both datasets (referenced as left-hand side and right-hand side statistics). Let's see what these parameters are:\n",
    "\n",
    "- `lhs_statistics`: Required parameter. Expects an instance of `DatasetFeatureStatisticsList `.\n",
    "\n",
    "\n",
    "- `rhs_statistics`: Expects an instance of `DatasetFeatureStatisticsList ` to compare with `lhs_statistics`.\n",
    "\n",
    "\n",
    "- `lhs_name`: Name of the `lhs_statistics` dataset.\n",
    "\n",
    "\n",
    "- `rhs_name`: Name of the `rhs_statistics` dataset.\n",
    "\n",
    "For this case, remember to define the `lhs_statistics` protocol with the `eval_stats`, and the optional `rhs_statistics` protocol with the `train_stats`.\n",
    "\n",
    "Additionally, check the function for the protocol name declaration, and define the lhs and rhs names as `'EVAL_DATASET'` and `'TRAIN_DATASET'` respectively.\n",
    "\n",
    "**Task**: Generate the evaluation of the dataset statistics and call it *eval_stats*. Then visualize the differences between the evaluation and training data. Remember to use the two functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "graded": true,
    "id": "j_P0RLYlV6XG",
    "name": "eval_stats_visualize_statistics",
    "outputId": "951eda29-f0d1-4cda-bd11-ac68c6ce53f9"
   },
   "outputs": [],
   "source": [
    "# Generate evaluation dataset statistics\n",
    "# HINT: Remember to use the evaluation dataframe and to pass the stats_options (that you defined before) as an argument\n",
    "\n",
    "# Compare evaluation data with training data \n",
    "# HINT: Remember to use both the evaluation and training statistics with the lhs_statistics and rhs_statistics arguments\n",
    "# HINT: Assign the names of 'EVAL_DATASET' and 'TRAIN_DATASET' to the lhs and rhs protocols\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnXjzlbfBaAp"
   },
   "source": [
    "In the following you can test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "wnrxrpYWBaAp",
    "outputId": "64b6ddb7-b591-477e-c3fe-14257658d32e"
   },
   "outputs": [],
   "source": [
    "# get the number of features used to compute statistics\n",
    "print(f\"Number of features: {len(eval_stats.datasets[0].features)}\")\n",
    "\n",
    "# check the number of examples used\n",
    "print(f\"Number of examples: {eval_stats.datasets[0].num_examples}\")\n",
    "\n",
    "# check the column names of the first and last feature\n",
    "print(f\"First feature: {eval_stats.datasets[0].features[0].path.step[0]}\")\n",
    "print(f\"Last feature: {eval_stats.datasets[0].features[-1].path.step[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWkGu7fLBaAs"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "Number of features: 48\n",
    "Number of examples: 15265\n",
    "First feature: race\n",
    "Last feature: readmitted\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COwqJqf8aLGx"
   },
   "source": [
    "<a name='ex-5'></a>\n",
    "### Detecting Anomalies ###\n",
    "\n",
    "At this point, you should ask if your evaluation dataset matches the schema from your training dataset. For instance, if you scroll through the output cell in the previous exercise, you can see that the categorical feature **glimepiride-pioglitazone** has 1 unique value in the training set while the evaluation dataset has 2. You can verify with the built-in Pandas `describe()` method as well.\n",
    "\n",
    "**Task**: Use `describe()` on the feature \"glimepiride-pioglitazone\" in both the training data and the evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ED7roT_BaAs",
    "outputId": "a1eb2dc7-0615-42b8-ae3d-6adb88ab7304"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_StNNcrRBaAv",
    "outputId": "f781c646-37ec-4995-903a-b8d871ba1b3c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82j-Yq4vBaAw"
   },
   "source": [
    "It is possible but highly inefficient to visually inspect and determine all the anomalies. So, let's instead use TFDV functions to detect and display these. \n",
    "You can use the function [`tfdv.validate_statistics()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/validate_statistics) for detecting anomalies and [`tfdv.display_anomalies()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/display_anomalies) for displaying them.\n",
    "\n",
    "The `validate_statistics()` method has two required arguments:\n",
    "- an instance of `DatasetFeatureStatisticsList`\n",
    "- an instance of `Schema`\n",
    "\n",
    "**Task**: Detect the anomalies and name them *anomalies*, and then visualize the anomalies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "QBUX-ocHs5NK",
    "outputId": "726df003-1293-4944-c6bb-320c317f1b4e"
   },
   "outputs": [],
   "source": [
    "# HINTS: Pass the statistics and schema parameters into the validation function \n",
    "\n",
    " \n",
    "# HINTS: Display input anomalies by using the calculated anomalies\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mb4gTlGOBaAw"
   },
   "source": [
    "You should see detected anomalies in the `medical_specialty` and `glimepiride-pioglitazone` features by running the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzxx1gBpJIBa"
   },
   "source": [
    "<a name='ex-6'></a>\n",
    "### Fix evaluation anomalies in the schema\n",
    "\n",
    "The evaluation data has records with values for the features **glimepiride-pioglitazone** and **medical_speciality**  that were not included in the schema generated from the training data. You can fix this by adding the new values that exist in the evaluation dataset to the domain of these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1vZ1MJQBaAx"
   },
   "source": [
    "To get the `domain` of a particular feature you can use [`tfdv.get_domain()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/get_domain).\n",
    "\n",
    "You can use the `append()` method to the `value` property of the returned `domain` to add strings to the valid list of values. To be more explicit, given a domain you can do something like:\n",
    "\n",
    "```python\n",
    "domain.value.append(\"feature_value\")\n",
    "\n",
    "```\n",
    "\n",
    "**Task**: Start by getting the domain associated with the feature 'glimepiride-pioglitazone', and name it *glimepiride_pioglitazone_domain*. Then the missing value 'Steady' should be appended to the domain. Go through the same procedure for the feature 'medical_specialty', where the missing value is called 'Neurophysiology'. Then recalculate and redisplay the anomalies with the new schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "legN2nXLWZAc",
    "outputId": "ded15a2c-54c5-4b27-e1e5-c9e51bfe33d2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zer7f04DBaA0"
   },
   "source": [
    "If you did the exercise correctly, you should see *\"No anomalies found.\"* after running the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZ1P4ucHJj5o"
   },
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Schema Environments\n",
    "\n",
    "By default, all datasets in a pipeline should use the same schema. However, there are some exceptions. \n",
    "\n",
    "For example, the **label column is dropped in the serving set** so this will be flagged when comparing with the training set schema. \n",
    "\n",
    "**In this case, introducing slight schema variations is necessary.**\n",
    "\n",
    "<a name='ex-7'></a>\n",
    "### Check anomalies in the serving set\n",
    "\n",
    "Now you are going to check for anomalies in the **serving data**. The process is very similar to the one you previously did for the evaluation data with a little change. \n",
    "\n",
    "**Task**: Create a new `tfdv.StatsOptions` called 'options', which is aware of the information provided by the schema and use it when generating statistics from the serving DataFrame.\n",
    "Then calculate and display anomalies using the generated serving statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReZxYguLBaA0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhtYF8aAczpd",
    "outputId": "ad5fb0af-a08d-4a50-e802-f2b9bb0d8239"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIRf9IS1BaA1"
   },
   "source": [
    "You should see that `metformin-rosiglitazone`, `metformin-pioglitazone`, `payer_code` and `medical_specialty` features have an anomaly (i.e. Unexpected string values) which is less than 1%. \n",
    "\n",
    "Let's **relax the anomaly detection constraints** for the last two of these features by defining the `min_domain_mass` of the feature's distribution constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "maABh2z0BaA1",
    "outputId": "f60d9863-bc6b-40a4-ad56-0250188b8f67"
   },
   "outputs": [],
   "source": [
    "# This relaxes the minimum fraction of values that must come from the domain for the feature.\n",
    "\n",
    "# Get the feature and relax to match 90% of the domain\n",
    "payer_code = tfdv.get_feature(schema, 'payer_code')\n",
    "payer_code.distribution_constraints.min_domain_mass = 0.9 \n",
    "\n",
    "# Get the feature and relax to match 90% of the domain\n",
    "medical_specialty = tfdv.get_feature(schema, 'medical_specialty')\n",
    "medical_specialty.distribution_constraints.min_domain_mass = 0.9 \n",
    "\n",
    "# Detect anomalies with the updated constraints\n",
    "calculate_and_display_anomalies(serving_stats, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4fnMiqxBaA1"
   },
   "source": [
    "If the `payer_code` and `medical_specialty` are no longer part of the output cell, then the relaxation worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g9fd4hqBaA1"
   },
   "source": [
    "<a name='ex-8'></a>\n",
    "### Modifying the Domain\n",
    "\n",
    "Let's investigate the possible cause of the anomalies for the other features, namely `metformin-pioglitazone` and `metformin-rosiglitazone`. From the output of the previous exercise, you'll see that the `anomaly long description` says: \"Examples contain values missing from the schema: Steady (<1%)\". \n",
    "You can redisplay the schema and look at the domain of these features to verify this statement.\n",
    "\n",
    "When you inferred the schema at the start of this lab, it's possible that some  values were not detected in the training data so it was not included in the expected domain values of the feature's schema. In the case of `metformin-rosiglitazone` and `metformin-pioglitazone`, the value \"Steady\" is indeed missing. You will just see \"No\" in the domain of these two features after running the code cell below.\n",
    "\n",
    "**Task**: Use the `tfdv.display_schema()` function to display the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "fFQ5b4kPBaA1",
    "outputId": "65ae4ad6-8b0d-497a-d1a4-43ff29ad19c6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td57Wnr0BaA2"
   },
   "source": [
    "Towards the bottom of the Domain-Values pairs of the cell above, you can see that many features (including **'metformin'**) have the same values: `['Down', 'No', 'Steady', 'Up']`. These values are common to many features including the ones with missing values during schema inference. \n",
    "\n",
    "TFDV allows you to modify the domains of some features to match an existing domain. To address the detected anomaly, you can **set the domain** of these features to the domain of the `metformin` feature.\n",
    "\n",
    "**Task**: Set the domain of a feature list to an existing feature domain. For this, use the [`tfdv.set_domain()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/set_domain) function, which has the following parameters:\n",
    "\n",
    "- `schema`: The schema\n",
    "\n",
    "\n",
    "- `feature_path`: The name of the feature whose domain needs to be set.\n",
    "\n",
    "\n",
    "- `domain`: A domain protocol buffer or the name of a global string domain present in the input schema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ACLvPPTkZfp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMOQw7kgBaA5"
   },
   "source": [
    "**Task**: Modify the domain of the features defined in the `domain_change_features` list below to be equal to **metformin's domain** to address the anomalies found. Use the function `modify_domain_of_features`, and then display the new schema. \n",
    "\n",
    "**Since you are overriding the existing domain of the features, it is normal to get a warning so you don't do this by accident.**\n",
    "\n",
    "Remember to display the new schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_jNanzjfeS-"
   },
   "outputs": [],
   "source": [
    "domain_change_features = ['repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', \n",
    "                          'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', \n",
    "                          'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', \n",
    "                          'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', \n",
    "                          'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFSyddQYBaA6"
   },
   "source": [
    "In the following you can test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EUjkWgdBaA6"
   },
   "outputs": [],
   "source": [
    "# check that the domain of some features are now switched to `metformin`\n",
    "print(f\"Domain name of 'chlorpropamide': {tfdv.get_feature(schema, 'chlorpropamide').domain}\")\n",
    "print(f\"Domain values of 'chlorpropamide': {tfdv.get_domain(schema, 'chlorpropamide').value}\")\n",
    "print(f\"Domain name of 'repaglinide': {tfdv.get_feature(schema, 'repaglinide').domain}\")\n",
    "print(f\"Domain values of 'repaglinide': {tfdv.get_domain(schema, 'repaglinide').value}\")\n",
    "print(f\"Domain name of 'nateglinide': {tfdv.get_feature(schema, 'nateglinide').domain}\")\n",
    "print(f\"Domain values of 'nateglinide': {tfdv.get_domain(schema, 'nateglinide').value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApdTphXABaA7"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "Domain name of 'chlorpropamide': metformin\n",
    "Domain values of 'chlorpropamide': ['Down', 'No', 'Steady', 'Up']\n",
    "Domain name of 'repaglinide': metformin\n",
    "Domain values of 'repaglinide': ['Down', 'No', 'Steady', 'Up']\n",
    "Domain name of 'nateglinide': metformin\n",
    "Domain values of 'nateglinide': ['Down', 'No', 'Steady', 'Up']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwBJIKfvBaA7"
   },
   "source": [
    "Let's do a final check of anomalies to see if this solved the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlZn1JkbBaA7"
   },
   "outputs": [],
   "source": [
    "calculate_and_display_anomalies(serving_stats, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0o9ZAlcBaA8"
   },
   "source": [
    "You should now see the `metformin-pioglitazone` and `metformin-rosiglitazone` features dropped from the output anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJjh5rigc5xy"
   },
   "source": [
    "<a name='ex-9'></a>\n",
    "### Detecting anomalies with environments\n",
    "\n",
    "There is still one thing to address. The `readmitted` feature (which is the label column) showed up as an anomaly ('Column dropped'). Since labels are not expected in the serving data, let's tell TFDV to ignore this detected anomaly.\n",
    "\n",
    "This requirement of introducing slight schema variations can be expressed by using [environments](https://www.tensorflow.org/tfx/data_validation/get_started#schema_environments). In particular, features in the schema can be associated with a set of environments using `default_environment`, `in_environment` and `not_in_environment`.\n",
    "\n",
    "**Task**: Run the code below for the default schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "aCGOF79sBaA8",
    "outputId": "f8832e30-df43-417c-c868-509db946b5ca"
   },
   "outputs": [],
   "source": [
    "# All features are by default in both TRAINING and SERVING environments.\n",
    "schema.default_environment.append('TRAINING')\n",
    "schema.default_environment.append('SERVING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhIH3zyCBaA8"
   },
   "source": [
    "Complete the code below to exclude the `readmitted` feature from the `SERVING` environment.\n",
    "\n",
    "To achieve this, you can use the [`tfdv.get_feature()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/get_feature) function to get the `readmitted` feature from the inferred schema and use its `not_in_environment` attribute to specify that `readmitted` should be removed from the `SERVING` environment's schema. This **attribute is a list** so you will have to **append** the name of the environment that you wish to omit this feature for.\n",
    "\n",
    "To be more explicit, given a feature you can do something like:\n",
    "\n",
    "```python\n",
    "feature.not_in_environment.append('NAME_OF_ENVIRONMENT')\n",
    "```\n",
    "\n",
    "The function `tfdv.get_feature` receives the following parameters:\n",
    "\n",
    "- `schema`: The schema.\n",
    "- `feature_path`: The path of the feature to obtain from the schema. In this case this is equal to the name of the feature.\n",
    "\n",
    "**Task**: Specify that the 'readmitted' feature is not in SERVING environment. This is done by appending the serving environment  to the not_in_environment attribute of the feature. Then calculate the anomalies with the validate_statistics function by using the serving statistics, inferred schema and the serving environment parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "bnbnw8H6Lp2M",
    "outputId": "587ef775-4bb4-4a3e-fd32-215daae15f4b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6MXUVyUBaA9"
   },
   "source": [
    "You should see \"No anomalies found\" by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNTOk1c5BaA9"
   },
   "outputs": [],
   "source": [
    "# Display anomalies\n",
    "tfdv.display_anomalies(serving_anomalies_with_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_2-K1YDBaBA"
   },
   "source": [
    "Now you have succesfully addressed all anomaly-related issues!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yteMr3AGMYEp"
   },
   "source": [
    "<a name='7'></a>\n",
    "## 7 - Check for Data Drift and Skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Foe3aT1OcePh"
   },
   "source": [
    "During data validation, you also need to check for data drift and data skew between the training and serving data. You can do this by specifying the [skew_comparator and drift_comparator](https://www.tensorflow.org/tfx/data_validation/get_started#checking_data_skew_and_drift) in the schema. \n",
    "\n",
    "Drift and skew is expressed in terms of [L-infinity distance](https://en.wikipedia.org/wiki/Chebyshev_distance) which evaluates the difference between vectors as the greatest of the differences along any coordinate dimension.\n",
    "\n",
    "You can set the threshold distance so that you receive warnings when the drift is higher than is acceptable.  Setting the correct distance is typically an iterative process requiring domain knowledge and experimentation.\n",
    "\n",
    "In the below code you can check the skew in the *diabetesMed* feature.\n",
    "\n",
    "**Task**: Write code to check the drift in the *payer_code* feature and name it 'payer_code'. Hint, use the 'drift_comparator' instead of 'skew_comparator' in the code. Then calculate the anomalies by using the `tfdv.validate_statistics()` function and name it 'skew_drift_anomalies', and display them by the `tfdv.display_anomalies()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEUsZm_rOd1Q",
    "outputId": "edbfb6eb-7176-43c9-883f-dddeb6f8cc63"
   },
   "outputs": [],
   "source": [
    "# Calculate skew for the diabetesMed feature\n",
    "diabetes_med = tfdv.get_feature(schema, 'diabetesMed')\n",
    "diabetes_med.skew_comparator.infinity_norm.threshold = 0.03 # domain knowledge helps to determine this threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK3641x6BaBB"
   },
   "source": [
    "In both of these cases, the detected anomaly distance is not too far from the threshold value of `0.03`. For this exercise, let's accept this as within bounds (i.e. you can set the distance to something like `0.035` instead).\n",
    "\n",
    "**However, if the anomaly truly indicates a skew and drift, then further investigation is necessary as this could have a direct impact on model performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ5saC9eWvHx"
   },
   "source": [
    "<a name='8'></a>\n",
    "## 8 - Freeze the schema\n",
    "\n",
    "Now that the schema has been reviewed, you will store the schema in a file in its \"frozen\" state. This can be used to validate incoming data once your application goes live to your users.\n",
    "\n",
    "This is pretty straightforward using Tensorflow's `io` utils and TFDV's [`write_schema_text()`](https://www.tensorflow.org/tfx/data_validation/api_docs/python/tfdv/write_schema_text) function.\n",
    "\n",
    "**Task**: Set the correct output directory and locate your schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydkL4DkIWn18"
   },
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "OUTPUT_DIR = \"output\"\n",
    "file_io.recursive_create_dir(OUTPUT_DIR)\n",
    "\n",
    "# Use TensorFlow text output format pbtxt to store the schema\n",
    "schema_file = os.path.join(OUTPUT_DIR, 'schema.pbtxt')\n",
    "\n",
    "# write_schema_text function expect the defined schema and output path as parameters\n",
    "tfdv.write_schema_text(schema, schema_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CBS_Assignment.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "MLEPC2W1-1",
    "MLEPC2W1-2",
    "MLEPC2W1-3",
    "MLEPC2W1-4",
    "MLEPC2W1-5",
    "MLEPC2W1-6",
    "MLEPC2W1-7",
    "MLEPC2W1-8",
    "MLEPC2W1-9"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "93cc691b8e19f1b1baece87a808e22c5fb6a128452650ac87b58bb54938a07f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
